{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cdbdfe78aeb4116a4be34094aab92d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f7e616bc5144e1b476803b975648e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f281573645847aa8b9b75e10147f26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560c09abf41a4c239a3b4d034f403db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76951164d97946df97b3112ce433812b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18e2a6703b7481d988319b6a3257b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c5457e025d4549acfb83fce929a0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b66ce08b1040289f2e1d1da5d3f278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f6fc7563e64ab9aea3cb4d5cc4a49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b6fe586caa4451aabd19508a748078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dab40a0d00a4f96af4bea723c9ad9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1475c5070b435889da98676aa309ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbe31bed69c4d28bd849cde9a7b8633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545385d18ceb4401bb75a92986095d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer,util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 384)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = ['This framework generates embeddings from input sentence',\n",
    "            'sentences are list of strings']\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This framework generates embeddings from input sentence \n",
      " [-0.02806348 -0.02237359 -0.00474183  0.02845586  0.04651126] \n",
      " (384,)\n",
      "sentences are list of strings \n",
      " [ 0.04024431  0.0650033   0.05060358  0.05312231 -0.02137426] \n",
      " (384,)\n"
     ]
    }
   ],
   "source": [
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(sentence,'\\n', embedding[:5],'\\n', embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5398]])\n"
     ]
    }
   ],
   "source": [
    "emb1 = model.encode('i am eating apple')\n",
    "emb2 = model.encode('i like fruits')\n",
    "\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 384)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cosine similarity between all pairs\n",
    "\n",
    "sentences = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'A man is riding a horse.',\n",
    "          'A woman is playing violin.',\n",
    "          'Two men pushed carts through the woods.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'Someone in a gorilla costume is playing a set of drums.'\n",
    "          ]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "\n",
    "cos_sim = util.cos_sim(embeddings, embeddings)\n",
    "cos_sim.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get top 5 closest pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(0.7553), 0, 1), (tensor(-0.1050), 0, 2), (tensor(0.2474), 0, 3), (tensor(-0.0704), 0, 4), (tensor(-0.0333), 0, 5), (tensor(0.1707), 0, 6), (tensor(0.0476), 0, 7), (tensor(0.0630), 0, 8), (tensor(-0.0610), 1, 2), (tensor(0.1442), 1, 3), (tensor(-0.0809), 1, 4), (tensor(-0.0216), 1, 5), (tensor(0.1157), 1, 6), (tensor(0.0362), 1, 7), (tensor(0.0216), 1, 8), (tensor(-0.1088), 2, 3), (tensor(0.0217), 2, 4), (tensor(-0.0413), 2, 5), (tensor(-0.0928), 2, 6), (tensor(0.0231), 2, 7), (tensor(0.0247), 2, 8), (tensor(-0.0348), 3, 4), (tensor(0.0362), 3, 5), (tensor(0.7369), 3, 6), (tensor(0.0821), 3, 7), (tensor(0.1389), 3, 8), (tensor(-0.1654), 4, 5), (tensor(-0.0592), 4, 6), (tensor(0.1961), 4, 7), (tensor(0.2564), 4, 8), (tensor(0.0769), 5, 6), (tensor(-0.0380), 5, 7), (tensor(-0.0895), 5, 8), (tensor(0.0495), 6, 7), (tensor(0.1191), 6, 8), (tensor(0.6433), 7, 8)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_sentence_combinations = []\n",
    "\n",
    "for i in range(len(cos_sim)):\n",
    "    for j in range(i+1, len(cos_sim)):\n",
    "        all_sentence_combinations.append((cos_sim[i][j], i , j))\n",
    "\n",
    "print(all_sentence_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A man is eating food.', 'A man is eating a piece of bread.', tensor(0.7553))\n",
      "('A man is riding a horse.', 'A man is riding a white horse on an enclosed ground.', tensor(0.7369))\n",
      "('A monkey is playing drums.', 'Someone in a gorilla costume is playing a set of drums.', tensor(0.6433))\n",
      "('A woman is playing violin.', 'Someone in a gorilla costume is playing a set of drums.', tensor(0.2564))\n",
      "('A man is eating food.', 'A man is riding a horse.', tensor(0.2474))\n"
     ]
    }
   ],
   "source": [
    "all_sentence_combinations = sorted(all_sentence_combinations, key = lambda x:x[0], reverse=True)\n",
    "\n",
    "#top 5 similar pairs:\n",
    "for score, i, j in all_sentence_combinations[:5]:\n",
    "    print(f'{sentences[i], sentences[j], cos_sim[i][j]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9530b388923d48028831610ec07d5b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebec518fcf184ad69849016e6aeac60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3e646325bb4f988d771028fec7f8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73161681c294945aeae5ab2da704f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703ef67c31a34b1ab746e187c9e6eb41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/778 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b21c827b713436099e1856ff14a08cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/117 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1849b917612478db85c6482d7dddbaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15167410648d4e44910309f4adce2e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1874c107a014ddaa0636186b44a38f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c2c7247b6c4d20abadd73f5f3dabb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/294 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c856ba9cf4b4e8597c12fc8f63b47cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673cee555e5a489abd47a7fabc20f2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/464 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e2d5e94c5f410da21b281c12b45f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/v0m01sk/miniconda3/envs/ml/lib/python3.7/site-packages/transformers/configuration_utils.py:370: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('clips/mfaq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'corpus_id': 0, 'score': 0.5646325945854187}, {'corpus_id': 2, 'score': 0.5142340660095215}, {'corpus_id': 1, 'score': 0.4730038642883301}]]\n"
     ]
    }
   ],
   "source": [
    "question = \"<Q>How many models can I host on HuggingFace?\"\n",
    "answer_1 = \"<A>All plans come with unlimited private models and datasets.\"\n",
    "answer_2 = \"<A>AutoNLP is an automatic way to train and deploy state-of-the-art NLP models, seamlessly integrated with the Hugging Face ecosystem.\"\n",
    "answer_3 = \"<A>Based on how much training data and model variants are created, we send you a compute cost and payment link - as low as $10 per job.\"\n",
    "\n",
    "\n",
    "query_embedding = model.encode(question)\n",
    "corpus_embedding = model.encode([answer_1, answer_2, answer_3])\n",
    "\n",
    "print(util.semantic_search(query_embedding, corpus_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.7017179131507874, 'start': 20, 'end': 29, 'answer': 'unlimited'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "qa_model = pipeline(\"question-answering\")\n",
    "question = \"How many models can I host on HuggingFace?\"\n",
    "context = \"All plans come with unlimited private models and datasets.\"\n",
    "qa_model(question = question, context = context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# Corpus with example sentences\n",
    "corpus = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'Horse is eating grass.',\n",
    "          'A man is eating pasta.',\n",
    "          'A Woman is eating Biryani.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'The baby is carried by the woman',\n",
    "          'A man is riding a horse.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'Someone in a gorilla costume is playing a set of drums.',\n",
    "          'A cheetah is running behind its prey.',\n",
    "          'A cheetah chases prey on across a field.',\n",
    "          'The cheetah is chasing a man who is riding the horse.',\n",
    "          'man and women with their baby are watching cheetah in zoo'\n",
    "          ]\n",
    "\n",
    "corpus_embedding = embedder.encode(corpus)\n",
    "\n",
    "corpus_embedding = corpus_embedding/np.linalg.norm(corpus_embedding,axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_model = KMeans(n_clusters=3)\n",
    "clustering_model.fit(corpus_embedding)\n",
    "cluster_assignment = clustering_model.labels_\n",
    "cluster_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: ['A man is eating food.',\n",
       "  'A man is eating a piece of bread.',\n",
       "  'A man is eating pasta.',\n",
       "  'A Woman is eating Biryani.'],\n",
       " 1: ['Horse is eating grass.',\n",
       "  'A man is riding a horse.',\n",
       "  'A man is riding a white horse on an enclosed ground.',\n",
       "  'A monkey is playing drums.',\n",
       "  'Someone in a gorilla costume is playing a set of drums.',\n",
       "  'A cheetah is running behind its prey.',\n",
       "  'A cheetah chases prey on across a field.',\n",
       "  'The cheetah is chasing a man who is riding the horse.'],\n",
       " 0: ['The girl is carrying a baby.',\n",
       "  'The baby is carried by the woman',\n",
       "  'man and women with their baby are watching cheetah in zoo']}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_sentences = {}\n",
    "\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    if cluster_id not in clustered_sentences:\n",
    "        clustered_sentences[cluster_id]=[]\n",
    "\n",
    "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
    "\n",
    "clustered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d0a60b1ae513fa79b951594dd60d77960b80fef24d687a1ebfccceb5adf7ba4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
