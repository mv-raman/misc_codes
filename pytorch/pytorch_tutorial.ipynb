{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4632, 0.8653, 0.0556],\n",
      "         [0.2376, 0.1276, 0.2664]],\n",
      "\n",
      "        [[0.2643, 0.9560, 0.3486],\n",
      "         [0.6495, 0.7348, 0.8742]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "x = torch.rand(2, 2, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2, 2, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64 torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, 3, dtype=torch.double)\n",
    "print(x.dtype, x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 0.1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.5, 0.1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1469, 0.2928],\n",
      "        [0.7931, 0.3426]])\n",
      "tensor([[0.5981, 0.2524],\n",
      "        [0.0371, 0.4493]])\n",
      "tensor([[0.7450, 0.5452],\n",
      "        [0.8303, 0.7918]])\n",
      "tensor([[0.7450, 0.5452],\n",
      "        [0.8303, 0.7918]])\n",
      "tensor([[0.7450, 0.5452],\n",
      "        [0.8303, 0.7918]])\n",
      "tensor([[-0.5981, -0.2524],\n",
      "        [-0.0371, -0.4493]])\n",
      "tensor([[-0.5981, -0.2524],\n",
      "        [-0.0371, -0.4493]])\n",
      "tensor([[0.1094, 0.1596],\n",
      "        [0.6585, 0.2713]])\n",
      "tensor([[0.1972, 0.5371],\n",
      "        [0.9553, 0.4326]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "z = x + y\n",
    "print(z)\n",
    "z = torch.add(x, y)\n",
    "print(z)\n",
    "\n",
    "y.add_(x)\n",
    "print(y)\n",
    "\n",
    "z = x - y\n",
    "print(z)\n",
    "z = torch.sub(x,y)\n",
    "print(z)\n",
    "\n",
    "z = torch.mul(x, y)\n",
    "print(z)\n",
    "z = torch.div(x, y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5652, 0.0667, 0.6182],\n",
      "        [0.0082, 0.9264, 0.9179],\n",
      "        [0.7790, 0.7128, 0.1523],\n",
      "        [0.1834, 0.3410, 0.0509],\n",
      "        [0.0660, 0.7429, 0.7391]])\n",
      "tensor([0.5652, 0.0082, 0.7790, 0.1834, 0.0660])\n",
      "tensor([0.0082, 0.9264, 0.9179])\n",
      "0.15232282876968384\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "print(x[:,0])\n",
    "print(x[1,:])\n",
    "print(x[2,2].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1563, 0.8618, 0.4270, 0.8844],\n",
      "        [0.9901, 0.5636, 0.0232, 0.9692],\n",
      "        [0.0907, 0.3561, 0.3774, 0.2916],\n",
      "        [0.7227, 0.3870, 0.7014, 0.3612]])\n",
      "tensor([0.1563, 0.8618, 0.4270, 0.8844, 0.9901, 0.5636, 0.0232, 0.9692, 0.0907,\n",
      "        0.3561, 0.3774, 0.2916, 0.7227, 0.3870, 0.7014, 0.3612])\n",
      "tensor([[0.1563, 0.8618, 0.4270, 0.8844, 0.9901, 0.5636, 0.0232, 0.9692],\n",
      "        [0.0907, 0.3561, 0.3774, 0.2916, 0.7227, 0.3870, 0.7014, 0.3612]])\n",
      "torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 4)\n",
    "print(x)\n",
    "y = x.view(16)\n",
    "print(y)\n",
    "y = x.view(-1, 8)\n",
    "print(y)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5,)\n",
    "b = a.numpy()\n",
    "print(a, b)\n",
    "print(type(b))\n",
    "a.add_(1)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "print(a)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)\n",
    "a += 1\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    x = torch.ones(5, device=device)\n",
    "    y = torch.ones(5)\n",
    "    y = y.to(device)\n",
    "    z = x + y\n",
    "    z = z.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.3788,  1.2816, -0.1120], requires_grad=True)\n",
      "tensor([3.3788, 3.2816, 1.8880], grad_fn=<AddBackward0>)\n",
      "tensor(17.1666, grad_fn=<MeanBackward0>)\n",
      "tensor([4.5051, 4.3755, 2.5173])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x+2\n",
    "print(y)\n",
    "\n",
    "z = y*y*2\n",
    "z = z.mean()\n",
    "print(z)\n",
    "\n",
    "z.backward() # dz/dx\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# x = torch.randn(3, requires_grad=False)\n",
    "# print(x)\n",
    "\n",
    "# y = x+2\n",
    "# print(y)\n",
    "\n",
    "# z = y*y*2\n",
    "# z = z.mean()\n",
    "# print(z)\n",
    "\n",
    "# z.backward() # dz/dx\n",
    "# print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1655,  0.2442, -0.9923], requires_grad=True)\n",
      "tensor([1.8345, 2.2442, 1.0077], grad_fn=<AddBackward0>)\n",
      "tensor([ 6.7306, 10.0731,  2.0310], grad_fn=<MulBackward0>)\n",
      "tensor([7.3379e-01, 8.9769e+00, 4.0309e-03])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x+2\n",
    "print(y)\n",
    "\n",
    "z = y*y*2\n",
    "#z = z.mean()\n",
    "print(z)\n",
    "\n",
    "v = torch.tensor([.1, 1., .001], dtype=torch.float32)\n",
    "z.backward(v) # dz/dx\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.7476,  0.5875,  0.7222], requires_grad=True)\n",
      "tensor([0.2524, 2.5875, 2.7222])\n",
      "tensor([0.2524, 2.5875, 2.7222], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "# x.requires_grad_(False)\n",
    "# x.detach()\n",
    "# with torch.no_grad(): do operation\n",
    "\n",
    "# x.requires_grad_(False)\n",
    "# print(x)\n",
    "# y = x.detach()\n",
    "# print(y)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = x+2\n",
    "    print(y)\n",
    "y=x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "print(weights)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "\n",
    "    model_output.backward()\n",
    "\n",
    "    print(weights.grad)\n",
    "\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "#forward pass and compute loss\n",
    "\n",
    "y_hat = w * x\n",
    "loss = (y_hat - y)**2\n",
    "\n",
    "print(loss)\n",
    "\n",
    "#backward pass\n",
    "\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "\n",
    "#update weights\n",
    "#next forward and backward pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training: f(5)=0.000\n",
      "epoch1: w =1.200, loss = 30.00000000\n",
      "epoch2: w =1.680, loss = 4.79999924\n",
      "epoch3: w =1.872, loss = 0.76800019\n",
      "epoch4: w =1.949, loss = 0.12288000\n",
      "epoch5: w =1.980, loss = 0.01966083\n",
      "epoch6: w =1.992, loss = 0.00314570\n",
      "epoch7: w =1.997, loss = 0.00050332\n",
      "epoch8: w =1.999, loss = 0.00008053\n",
      "epoch9: w =1.999, loss = 0.00001288\n",
      "epoch10: w =2.000, loss = 0.00000206\n",
      "prediction after training: f(5)=9.999\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "#f = w*x, f=2*x\n",
    "\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
    "\n",
    "w=0.0\n",
    "\n",
    "#model prediction\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "#loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "#gradient\n",
    "# MSE = 1/N * (w*x -y)**2\n",
    "# dJ/dw = 1/N 2x (w*x - y)\n",
    "\n",
    "def gradient(x, y, y_predicted):\n",
    "    return np.dot(2*x, y_predicted-y).mean()\n",
    "\n",
    "\n",
    "print(f'prediction before training: f(5)={forward(5):.3f}')\n",
    "\n",
    "# training\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters=10\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    #loss\n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    #gradients\n",
    "    dw = gradient(X, y, y_pred)\n",
    "\n",
    "    #update weights\n",
    "    w -= learning_rate * dw\n",
    "\n",
    "    if epoch % 1==0:\n",
    "        print(f'epoch{epoch+1}: w ={w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "\n",
    "print(f'prediction after training: f(5)={forward(5):.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training: f(5)=0.000\n",
      "epoch1: w =0.300, loss = 30.00000000\n",
      "epoch11: w =1.665, loss = 1.16278565\n",
      "epoch21: w =1.934, loss = 0.04506890\n",
      "epoch31: w =1.987, loss = 0.00174685\n",
      "epoch41: w =1.997, loss = 0.00006770\n",
      "epoch51: w =1.999, loss = 0.00000262\n",
      "epoch61: w =2.000, loss = 0.00000010\n",
      "epoch71: w =2.000, loss = 0.00000000\n",
      "epoch81: w =2.000, loss = 0.00000000\n",
      "epoch91: w =2.000, loss = 0.00000000\n",
      "prediction after training: f(5)=10.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#f = w*x, f=2*x\n",
    "\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype = torch.float32, requires_grad=True)\n",
    "\n",
    "#model prediction\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "#loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "print(f'prediction before training: f(5)={forward(5):.3f}')\n",
    "\n",
    "# training\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iters=100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    #loss\n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    #gradients = backward pass\n",
    "    l.backward() # dl/dw \n",
    "\n",
    "    #update weights but not part of computation graph\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "    \n",
    "    # zero gradients\n",
    "    w.grad.zero_()\n",
    "\n",
    "    if epoch % 10==0:\n",
    "        print(f'epoch{epoch+1}: w ={w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "\n",
    "print(f'prediction after training: f(5)={forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression with torch methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "prediction before training: f(5)=-3.345\n",
      "epoch1: w =0.011, loss = 50.82451248\n",
      "epoch11: w =1.561, loss = 0.26312882\n",
      "epoch21: w =1.611, loss = 0.22014369\n",
      "epoch31: w =1.634, loss = 0.19522324\n",
      "epoch41: w =1.656, loss = 0.17312734\n",
      "epoch51: w =1.676, loss = 0.15353248\n",
      "epoch61: w =1.695, loss = 0.13615525\n",
      "epoch71: w =1.713, loss = 0.12074482\n",
      "epoch81: w =1.729, loss = 0.10707863\n",
      "epoch91: w =1.745, loss = 0.09495924\n",
      "prediction after training: f(5)=9.503\n"
     ]
    }
   ],
   "source": [
    "# 1. Design model(input size, output size, forward pass)\n",
    "# 2. Construct loss and optimizer\n",
    "# 3. Training loop\n",
    "#   - forward pass : compute prediction\n",
    "#   - backward pass : gradients\n",
    "#   - update weights\n",
    "     \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "\n",
    "X_test = torch.tensor([5], dtype = torch.float32)\n",
    "\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "\n",
    "# model = nn.Linear(input_size, output_size)\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # define Layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "        \n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "print(f'prediction before training: f(5)={model(X_test).item():.3f}')\n",
    "\n",
    "# training\n",
    "\n",
    "learning_rate = 0.02\n",
    "n_iters=100\n",
    "\n",
    "#loss = MSE\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "\n",
    "    y_pred = model(X)\n",
    "\n",
    "    #loss\n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    #gradients = backward pass\n",
    "    l.backward() # dl/dw \n",
    "\n",
    "    #update weights but not part of computation graph\n",
    "    optimizer.step()\n",
    "    \n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10==0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f'epoch{epoch+1}: w ={w[0][0].item():.3f}, loss = {l:.8f}')\n",
    "\n",
    "\n",
    "print(f'prediction after training: f(5)={model(X_test).item():.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch:10, loss = 4429.3950\n",
      "eopch:20, loss = 3304.7319\n",
      "eopch:30, loss = 2490.6821\n",
      "eopch:40, loss = 1900.8475\n",
      "eopch:50, loss = 1473.0593\n",
      "eopch:60, loss = 1162.5229\n",
      "eopch:70, loss = 936.9153\n",
      "eopch:80, loss = 772.8853\n",
      "eopch:90, loss = 653.5429\n",
      "eopch:100, loss = 566.6584\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#0.prepare dataset\n",
    "\n",
    "\n",
    "X_numpy , y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20,\n",
    "                                             random_state=1)\n",
    "\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "\n",
    "#1.model\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "\n",
    "#2.loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "#3.training loop\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # forward pass and loss\n",
    "\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, y)\n",
    "\n",
    "    #backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    #update\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1)%10 == 0:\n",
    "        print(f'eopch:{epoch+1}, loss = {loss.item():.4f}')\n",
    "              \n",
    "\n",
    "\n",
    "predicted = model(X).detach().numpy()\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, loss= 0.6247\n",
      "epoch:20, loss= 0.5043\n",
      "epoch:30, loss= 0.4304\n",
      "epoch:40, loss= 0.3803\n",
      "epoch:50, loss= 0.3438\n",
      "epoch:60, loss= 0.3159\n",
      "epoch:70, loss= 0.2938\n",
      "epoch:80, loss= 0.2756\n",
      "epoch:90, loss= 0.2605\n",
      "epoch:100, loss= 0.2475\n",
      "accuracy = 0.9211\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0. prepare data\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1234)\n",
    "\n",
    "# scale\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "# 1. model\n",
    "# f= wx+b , sigmoid\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        return y_predicted\n",
    "\n",
    "model = LogisticRegression(n_features)\n",
    "\n",
    "# 2. loss and optmizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3. training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    #forward pass and loss \n",
    "    y_predicted = model(X_train)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "    #backward pass\n",
    "    loss.backward()\n",
    "    #updates\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1)%10==0:\n",
    "        print(f'epoch:{epoch+1}, loss= {loss.item():.4f}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() /float(y_test.shape[0])\n",
    "    print(f'accuracy = {acc:.4f}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "epoch = 1 forward and backward pass of all training samples\n",
    "\n",
    "batch_size = number of training samples in one forward and backward pass\n",
    "\n",
    "number of iterations = number of passes, each pass using [batch_size] number of samples\n",
    "\n",
    "eg: 100 samples, batch_size = 20, 100/20 = 5 iterations for 1 epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n",
      "epoch 1/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 1/2, step 45/45, inputs torch.Size([2, 13])\n",
      "epoch 2/2, step 5/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 10/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 15/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 20/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 25/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 30/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 35/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 40/45, inputs torch.Size([4, 13])\n",
      "epoch 2/2, step 45/45, inputs torch.Size([2, 13])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "#torchvision.datsets.MNIST() # fashion-mnist,cifar,coco\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        # data loading\n",
    "        xy = np.loadtxt('./data/wine.csv', delimiter=',', dtype=np.float32,skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[:, 1:]) # n_samples, n_features\n",
    "        self.y = torch.from_numpy(xy[:,[0]]) # n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        #len(dataset)\n",
    "        return self.n_samples\n",
    "    \n",
    "dataset = WineDataset()\n",
    "# first_data = dataset[0]\n",
    "# features, labels = first_data\n",
    "# print(features, labels)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "# dataiter = iter(dataloader)\n",
    "# data = next(dataiter)\n",
    "# features, labels = data\n",
    "# print(features, labels)\n",
    "\n",
    "## training loop\n",
    "\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        #forward pass , update weights\n",
    "        if (i+1)%5==0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03] [1.]\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
      "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
      "        2.1300e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        # data loading\n",
    "        xy = np.loadtxt('./data/wine.csv', delimiter=',', dtype=np.float32,skiprows=1)\n",
    "        self.x = xy[:, 1:] # n_samples, n_features\n",
    "        self.y = xy[:,[0]] # n_samples, 1\n",
    "        self.n_samples = xy.shape[0]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #dataset[0]\n",
    "        sample = self.x[index], self.y[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        #len(dataset)\n",
    "        return self.n_samples\n",
    "    \n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "\n",
    "\n",
    "\n",
    "class MulTransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    \n",
    "    def __call__(self,sample):\n",
    "        inputs, targets = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, targets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = WineDataset(transform=None)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)\n",
    "\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
    "\n",
    "dataset = WineDataset(transform=composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
      "torch softmax: tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "outputs = softmax(x)\n",
    "print('softmax numpy:', outputs)\n",
    "\n",
    "\n",
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim=0)\n",
    "print('torch softmax:', outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 numpy : 0.3567\n",
      "loss2 numpy : 2.3026\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss # / float(predicted.shape[0])\n",
    "\n",
    "# y must be one hot encoded\n",
    "Y = np.array([1, 0, 0])\n",
    "\n",
    "\n",
    "Y_pred_good = np.array([.7, .2, .1 ])\n",
    "Y_pred_bad = np.array([.1, .3, .6 ])\n",
    "\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "\n",
    "print(f'loss1 numpy : {l1:.4f}')\n",
    "print(f'loss2 numpy : {l2:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 torch : 0.4170\n",
      "loss2 torch : 1.8406\n",
      "tensor([0])\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "## cross entropy loss applies nn.LogSoftmax + nn.NLLLoss( negative log likelihood loss)\n",
    "# no softmax in last layer\n",
    "\n",
    "# Y has class labels , not one hot\n",
    "# y pred has to be raw scores (logits), no softmax\n",
    "\n",
    "Y = torch.tensor([0])\n",
    "# n_sample * n_classes = 1*3\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
    "\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(f'loss1 torch : {l1:.4f}')\n",
    "print(f'loss2 torch : {l2:.4f}')\n",
    "\n",
    "_, predictions1 = torch.max(Y_pred_good,1)\n",
    "_, predictions2 = torch.max(Y_pred_bad,1)\n",
    "\n",
    "print(predictions1)\n",
    "print(predictions2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 torch : 0.3018\n",
      "loss2 torch : 1.6242\n",
      "tensor([2, 0, 1])\n",
      "tensor([0, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "## cross entropy loss applies nn.LogSoftmax + nn.NLLLoss( negative log likelihood loss)\n",
    "# no softmax in last layer\n",
    "\n",
    "# Y has class labels , not one hot\n",
    "# y pred has to be raw scores (logits), no softmax\n",
    "\n",
    "Y = torch.tensor([2, 0, 1])\n",
    "# n_sample * n_classes = 3*3\n",
    "Y_pred_good = torch.tensor([[.1, 1.0, 2.1], [2.0, 1.0, 0.1], [.1, 3.0, 0.1]])\n",
    "Y_pred_bad = torch.tensor([[2.1, 1.0, 0.1], [0.1, 1.0, 2.1], [0.1, 3.0, 0.1]])\n",
    "\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(f'loss1 torch : {l1:.4f}')\n",
    "print(f'loss2 torch : {l2:.4f}')\n",
    "\n",
    "_, predictions1 = torch.max(Y_pred_good,1)\n",
    "_, predictions2 = torch.max(Y_pred_bad,1)\n",
    "\n",
    "print(predictions1)\n",
    "print(predictions2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed forward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/2, step 100/600, loss=0.3420\n",
      "epoch 1/2, step 200/600, loss=0.4789\n",
      "epoch 1/2, step 300/600, loss=0.2963\n",
      "epoch 1/2, step 400/600, loss=0.2266\n",
      "epoch 1/2, step 500/600, loss=0.2246\n",
      "epoch 1/2, step 600/600, loss=0.2734\n",
      "epoch 2/2, step 100/600, loss=0.1678\n",
      "epoch 2/2, step 200/600, loss=0.2060\n",
      "epoch 2/2, step 300/600, loss=0.2300\n",
      "epoch 2/2, step 400/600, loss=0.1574\n",
      "epoch 2/2, step 500/600, loss=0.2537\n",
      "epoch 2/2, step 600/600, loss=0.3160\n",
      "accuracy = 95.05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#device config\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# hyper parameters\n",
    "\n",
    "input_size = 784 # 28*28 \n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = .001\n",
    "\n",
    "## MNIST\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=False,\n",
    "                                           transform=transforms.ToTensor())\n",
    " \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False,)\n",
    "\n",
    "# examples = iter(train_loader)\n",
    "# samples, labels = next(examples)\n",
    "# print(samples.shape, labels.shape)\n",
    "\n",
    "# for i in range(6):\n",
    "#     plt.subplot(2,3, i+1)\n",
    "#     plt.imshow(samples[i][0], cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# loss and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "## training loop\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 100, 1, 28, 28\n",
    "        # 100,784\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 ==0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss={loss.item():.4f}')\n",
    "\n",
    "\n",
    "## test\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'accuracy = {acc}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convolution NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [2000/12500], Loss: 2.3028\n",
      "Epoch [1/5], Step [4000/12500], Loss: 2.2939\n",
      "Epoch [1/5], Step [6000/12500], Loss: 2.2722\n",
      "Epoch [1/5], Step [8000/12500], Loss: 2.3048\n",
      "Epoch [1/5], Step [10000/12500], Loss: 2.1959\n",
      "Epoch [1/5], Step [12000/12500], Loss: 2.3988\n",
      "Epoch [2/5], Step [2000/12500], Loss: 2.1254\n",
      "Epoch [2/5], Step [4000/12500], Loss: 2.1424\n",
      "Epoch [2/5], Step [6000/12500], Loss: 1.5450\n",
      "Epoch [2/5], Step [8000/12500], Loss: 2.2758\n",
      "Epoch [2/5], Step [10000/12500], Loss: 1.8076\n",
      "Epoch [2/5], Step [12000/12500], Loss: 1.7408\n",
      "Epoch [3/5], Step [2000/12500], Loss: 1.6560\n",
      "Epoch [3/5], Step [4000/12500], Loss: 2.4847\n",
      "Epoch [3/5], Step [6000/12500], Loss: 1.3073\n",
      "Epoch [3/5], Step [8000/12500], Loss: 1.6418\n",
      "Epoch [3/5], Step [10000/12500], Loss: 1.6553\n",
      "Epoch [3/5], Step [12000/12500], Loss: 1.4791\n",
      "Epoch [4/5], Step [2000/12500], Loss: 1.8236\n",
      "Epoch [4/5], Step [4000/12500], Loss: 1.6149\n",
      "Epoch [4/5], Step [6000/12500], Loss: 1.1042\n",
      "Epoch [4/5], Step [8000/12500], Loss: 1.9742\n",
      "Epoch [4/5], Step [10000/12500], Loss: 1.4654\n",
      "Epoch [4/5], Step [12000/12500], Loss: 1.5689\n",
      "Epoch [5/5], Step [2000/12500], Loss: 1.3896\n",
      "Epoch [5/5], Step [4000/12500], Loss: 1.8323\n",
      "Epoch [5/5], Step [6000/12500], Loss: 1.2604\n",
      "Epoch [5/5], Step [8000/12500], Loss: 1.1488\n",
      "Epoch [5/5], Step [10000/12500], Loss: 1.1124\n",
      "Epoch [5/5], Step [12000/12500], Loss: 1.2109\n",
      "finished Training\n",
      "accuracy of the network: 49.33 %\n",
      "accuracy of plane: 49.7 %\n",
      "accuracy of car: 78.9 %\n",
      "accuracy of bird: 29.0 %\n",
      "accuracy of cat: 38.6 %\n",
      "accuracy of deer: 38.0 %\n",
      "accuracy of dog: 33.7 %\n",
      "accuracy of frog: 63.1 %\n",
      "accuracy of horse: 65.5 %\n",
      "accuracy of ship: 57.1 %\n",
      "accuracy of truck: 39.7 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_epochs = 5\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root = './data', train=True,\n",
    "                                             download=True, transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img/2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        #backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1)%2000 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('finished Training')\n",
    "\n",
    "PATH = './cnn.pth'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct +=(predicted ==labels).sum().item()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label==pred):\n",
    "                n_class_correct[label]+=1\n",
    "            n_class_samples[label]+=1\n",
    "\n",
    "acc = 100 * n_correct / n_samples\n",
    "print(f'accuracy of the network: {acc} %')\n",
    "\n",
    "for i in range(10):\n",
    "    acc = 100.0* n_class_correct[i] / n_class_samples[i]\n",
    "    print(f'accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "## complete model\n",
    "torch.save(arg, PATH)\n",
    "\n",
    "torch.load(PATH)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "## state dict\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "## model must be created again with parameters\n",
    "\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def foward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "model = Model(n_input_features=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1411,  0.0516,  0.1793, -0.0742,  0.2767,  0.0311]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0286], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "FILE = \"model.pth\" #pytorch\n",
    "torch.save(model, FILE)\n",
    "\n",
    "model = torch.load(FILE)\n",
    "model.eval()\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1411,  0.0516,  0.1793, -0.0742,  0.2767,  0.0311]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0286], requires_grad=True)\n",
      "OrderedDict([('linear.weight', tensor([[-0.1411,  0.0516,  0.1793, -0.0742,  0.2767,  0.0311]])), ('linear.bias', tensor([-0.0286]))])\n"
     ]
    }
   ],
   "source": [
    "FILE = \"model.pth\" #pytorch\n",
    "torch.save(model.state_dict(), FILE)\n",
    "\n",
    "loaded_model = Model(n_input_features=6)\n",
    "loaded_model.load_state_dict(torch.load(FILE))\n",
    "loaded_model.eval()\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "print(optimizer.state_dict())\n",
    "\n",
    "checkpoint = {\n",
    "    \"epoch\": 90,\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optim_state\": optimizer.state_dict()\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, \"checkpoint.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n",
      "OrderedDict([('linear.weight', tensor([[-0.1411,  0.0516,  0.1793, -0.0742,  0.2767,  0.0311]])), ('linear.bias', tensor([-0.0286]))])\n"
     ]
    }
   ],
   "source": [
    "loaded_checkpoint = torch.load(\"checkpoint.pth\")\n",
    "epoch = loaded_checkpoint['epoch']\n",
    "\n",
    "model = Model(n_input_features=6)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "optimizer.load_state_dict(checkpoint['optim_state'])\n",
    "\n",
    "print(optimizer.state_dict())\n",
    "print(model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
